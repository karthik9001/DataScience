{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Spam/Ham example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#https://www.kdnuggets.com/2020/07/spam-filter-python-naive-bayes-scratch.html\n",
    "import pandas as pd\n",
    "\n",
    "sms_spam = pd.read_csv('data\\spam.csv', sep=',', usecols = ['v1','v2'])\n",
    "\n",
    "sms_spam.columns=['Label', 'SMS']\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.8)\n",
    "\n",
    "# Split into training and test sets\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.864065\n",
       "spam    0.135935\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.873429\n",
       "spam    0.126571\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Convey my regards to him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[��_] anyway, many good evenings to u! s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>My sort code is  and acc no is . The bank is n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                           Convey my regards to him\n",
       "1   ham           [��_] anyway, many good evenings to u! s\n",
       "2   ham  My sort code is  and acc no is . The bank is n..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before cleaning\n",
    "training_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>convey my regards to him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>_  anyway  many good evenings to u  s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>my sort code is  and acc no is   the bank is n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                           convey my regards to him\n",
       "1   ham              _  anyway  many good evenings to u  s\n",
       "2   ham  my sort code is  and acc no is   the bank is n..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning\n",
    "training_set['SMS'] = training_set['SMS'].str.replace(\n",
    "   '\\W', ' ') # Removes punctuation\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "training_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "   for word in sms:\n",
    "      vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7719"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pura',\n",
       " 'rough',\n",
       " 'stone',\n",
       " 'ente',\n",
       " 'st',\n",
       " 'idk',\n",
       " 'violet',\n",
       " 'spouse',\n",
       " 'sleepin',\n",
       " '169',\n",
       " 'expired',\n",
       " 'rememberi',\n",
       " 'window',\n",
       " 'sender',\n",
       " 'had',\n",
       " 'deepak',\n",
       " 'bird',\n",
       " 'ah',\n",
       " 'uv',\n",
       " '07008009200',\n",
       " '3d',\n",
       " 'ahhhh',\n",
       " 'toledo',\n",
       " 'interviews',\n",
       " 'iq',\n",
       " '07815296484',\n",
       " 'cares',\n",
       " 'mnths',\n",
       " 'wan',\n",
       " 'things',\n",
       " 'ji',\n",
       " '26th',\n",
       " 'hall',\n",
       " 'vu',\n",
       " 'ful',\n",
       " 'made',\n",
       " 'boytoy',\n",
       " '09058097189',\n",
       " 's89',\n",
       " 'honey',\n",
       " 'madam',\n",
       " 'phd',\n",
       " 'thew',\n",
       " 'wahala',\n",
       " 'cooked',\n",
       " '12mths',\n",
       " 'eta',\n",
       " 'technologies',\n",
       " 'dosomething',\n",
       " 'responce',\n",
       " 'joy',\n",
       " '087147123779am',\n",
       " '0871',\n",
       " 'distance',\n",
       " 'waht',\n",
       " 'oil',\n",
       " 'specific',\n",
       " 'customer',\n",
       " 'biro',\n",
       " 'jacket',\n",
       " 'attention',\n",
       " 'wrking',\n",
       " 'geeeee',\n",
       " 'tok',\n",
       " 'calculation',\n",
       " 'kodthini',\n",
       " 'lily',\n",
       " 'lk',\n",
       " 'mumhas',\n",
       " 'theyre',\n",
       " 'bedrm',\n",
       " 'ron',\n",
       " 'siva',\n",
       " 'esaplanade',\n",
       " 'necessarily',\n",
       " 'clark',\n",
       " 'fingers',\n",
       " 'newquay',\n",
       " 'deals',\n",
       " 'waves',\n",
       " 'sack',\n",
       " 'concern',\n",
       " 'themob',\n",
       " 'mei',\n",
       " 'prakesh',\n",
       " 'adp',\n",
       " 'dancing',\n",
       " 'bookedthe',\n",
       " 'sorts',\n",
       " '391784',\n",
       " 'dai',\n",
       " 'wherre',\n",
       " 'doubt',\n",
       " 'fightng',\n",
       " 'sexy',\n",
       " 'least',\n",
       " 'purity',\n",
       " 'wins',\n",
       " 'clothes',\n",
       " 'wkend',\n",
       " 'bcum',\n",
       " 'loooooool',\n",
       " 'cds',\n",
       " 'drum',\n",
       " 'throw',\n",
       " 'westlife',\n",
       " 'meh',\n",
       " '09090900040',\n",
       " 'tons',\n",
       " 'plural',\n",
       " '2find',\n",
       " 'chasing',\n",
       " 'settling',\n",
       " 'bottom',\n",
       " 'polo',\n",
       " '85555',\n",
       " 'bookmark',\n",
       " 'totally',\n",
       " 'clarification',\n",
       " 'forwarding',\n",
       " 'ass',\n",
       " 'anonymous',\n",
       " 'click',\n",
       " 'll',\n",
       " 'hurt',\n",
       " '42810',\n",
       " 'flowers',\n",
       " 'vivek',\n",
       " 'ask',\n",
       " 'module',\n",
       " 'replying',\n",
       " 'nok',\n",
       " 'vomiting',\n",
       " '89545',\n",
       " 'in',\n",
       " 'unlike',\n",
       " '81618',\n",
       " '8am',\n",
       " '350',\n",
       " '87575',\n",
       " 'extract',\n",
       " 'are',\n",
       " 'anot',\n",
       " '09061744553',\n",
       " 'nothin',\n",
       " 'location',\n",
       " 'start',\n",
       " 'zaher',\n",
       " 'nokia6650',\n",
       " 'difficult',\n",
       " 'compensation',\n",
       " 'exist',\n",
       " 'bong',\n",
       " 'dirt',\n",
       " 'thia',\n",
       " 'stapati',\n",
       " 'gets',\n",
       " 'couch',\n",
       " 'dileep',\n",
       " 'deduct',\n",
       " 'wrote',\n",
       " 'bid',\n",
       " 'villa',\n",
       " 'bay',\n",
       " 'po',\n",
       " 'help',\n",
       " 'dressed',\n",
       " 'bowl',\n",
       " 'bahamas',\n",
       " 'phoned',\n",
       " 'pleassssssseeeeee',\n",
       " 'hands',\n",
       " 'avoiding',\n",
       " 'aah',\n",
       " 'chance',\n",
       " 'pop',\n",
       " 'gre',\n",
       " '48922',\n",
       " 'usmle',\n",
       " 'categories',\n",
       " 'needed',\n",
       " '09066362206',\n",
       " 'some1',\n",
       " 'habit',\n",
       " 'px3748',\n",
       " 'lucky',\n",
       " 'sportsx',\n",
       " 'handle',\n",
       " 'young',\n",
       " 'good',\n",
       " 'reminded',\n",
       " 'priority',\n",
       " 'surprised',\n",
       " 'g696ga',\n",
       " 'ticket',\n",
       " 'asshole',\n",
       " 'korli',\n",
       " 'ldn',\n",
       " 'jamz',\n",
       " 'miss',\n",
       " 'gender',\n",
       " 'pole',\n",
       " 'conditions',\n",
       " 'hungry',\n",
       " 'arts',\n",
       " '10k',\n",
       " 'uploaded',\n",
       " 'premarica',\n",
       " 'best',\n",
       " 'arab',\n",
       " 'rates',\n",
       " 'prabha',\n",
       " 'just',\n",
       " 'formally',\n",
       " 'b4',\n",
       " 'scorable',\n",
       " 'bear',\n",
       " 'wear',\n",
       " 'ppm',\n",
       " '09064011000',\n",
       " 'harish',\n",
       " 'happiness',\n",
       " 'apo',\n",
       " 'appreciate',\n",
       " 'sweetheart',\n",
       " 'hotmail',\n",
       " 'optout',\n",
       " 'library',\n",
       " 'ok',\n",
       " 'overa',\n",
       " 'features',\n",
       " 'even',\n",
       " '400',\n",
       " 'clearer',\n",
       " 'correctly',\n",
       " 'cell',\n",
       " 'lt',\n",
       " 'cartons',\n",
       " 'sight',\n",
       " 'quit',\n",
       " 'blankets',\n",
       " 'ceri',\n",
       " 'forevr',\n",
       " 'clever',\n",
       " 'colin',\n",
       " 'ams',\n",
       " '_thanks',\n",
       " 'txtx',\n",
       " '99',\n",
       " 'icicibank',\n",
       " 'buddy',\n",
       " 'sunshine',\n",
       " 'europe',\n",
       " 'dirty',\n",
       " 'hitler',\n",
       " 'baby',\n",
       " '16',\n",
       " 'toppoly',\n",
       " 'borderline',\n",
       " 'goodfriend',\n",
       " 'computer',\n",
       " 'actor',\n",
       " '450',\n",
       " 'ammo',\n",
       " 'cuddle',\n",
       " '2814032',\n",
       " 'phyhcmk',\n",
       " 'mumtaz',\n",
       " 'siguviri',\n",
       " 'goldviking',\n",
       " 'friend',\n",
       " 'reach',\n",
       " 'clue',\n",
       " 'specify',\n",
       " 'member',\n",
       " 'torture',\n",
       " 'exeter',\n",
       " 'specs',\n",
       " 'page',\n",
       " 'dawns',\n",
       " 'recount',\n",
       " 'l8r',\n",
       " 'mostly',\n",
       " 'toughest',\n",
       " '28days',\n",
       " '000',\n",
       " 'hooch',\n",
       " 'lemme',\n",
       " 'unsub',\n",
       " '4ward',\n",
       " 'reality',\n",
       " 'professional',\n",
       " 'washob',\n",
       " 'rajas',\n",
       " 'houseful',\n",
       " 'apologise',\n",
       " 'basically',\n",
       " 'via',\n",
       " '08701752560',\n",
       " 'value',\n",
       " 'fucks',\n",
       " 'korche',\n",
       " 'okey',\n",
       " 'semester',\n",
       " 'probthat',\n",
       " 'toothpaste',\n",
       " '731',\n",
       " 'documents',\n",
       " 'indians',\n",
       " '180',\n",
       " 'thinking',\n",
       " 'chart',\n",
       " 'ltdhelpdesk',\n",
       " 'leaves',\n",
       " 'fgkslpopw',\n",
       " 'items',\n",
       " 'wrc',\n",
       " 'jordan',\n",
       " 'invnted',\n",
       " 'edu',\n",
       " 'andros',\n",
       " 'subscribe6gbp',\n",
       " 'lyf',\n",
       " 'sips',\n",
       " '449050000301',\n",
       " 'enjoying',\n",
       " '69669',\n",
       " 'staff',\n",
       " 'fathima',\n",
       " 'irritates',\n",
       " 'xxxxxxxx',\n",
       " 'thnx',\n",
       " 'guide',\n",
       " 'downon',\n",
       " '35p',\n",
       " 'anyplaces',\n",
       " 'rub',\n",
       " 'bell',\n",
       " 'affairs',\n",
       " 'without',\n",
       " 'promise',\n",
       " 'lambda',\n",
       " 'nimbomsons',\n",
       " 'longer',\n",
       " 'mtmsg',\n",
       " 'gaytextbuddy',\n",
       " 'amazing',\n",
       " 'hols',\n",
       " 'called',\n",
       " 'collages',\n",
       " 'iff',\n",
       " 'missing',\n",
       " 'thnq',\n",
       " 'jesus',\n",
       " '8lb',\n",
       " '087123002209am',\n",
       " 'noe',\n",
       " 'dat',\n",
       " 'vth',\n",
       " 'words',\n",
       " 'questions',\n",
       " 'toa',\n",
       " 'postal',\n",
       " 'willpower',\n",
       " 'standing',\n",
       " 'collect',\n",
       " 'astne',\n",
       " 'maraikara',\n",
       " 'netcollex',\n",
       " 'nichols',\n",
       " 'wants',\n",
       " 'western',\n",
       " 'heal',\n",
       " 'lolnice',\n",
       " 'amrca',\n",
       " 'sara',\n",
       " 'audiitions',\n",
       " 'tip',\n",
       " 'knowing',\n",
       " 'witin',\n",
       " '08701417012',\n",
       " '50rcvd',\n",
       " 'vewy',\n",
       " 'fact',\n",
       " 'ami',\n",
       " 'nw',\n",
       " 'devouring',\n",
       " '008704050406',\n",
       " 'might',\n",
       " 'likely',\n",
       " 'gudnite',\n",
       " 'monoc',\n",
       " 'capital',\n",
       " 'natwest',\n",
       " 'fab',\n",
       " 'pretty',\n",
       " 'earning',\n",
       " 'jap',\n",
       " 'suits',\n",
       " 'end',\n",
       " 'lift',\n",
       " 'il',\n",
       " 'bottle',\n",
       " 'tick',\n",
       " 'yup',\n",
       " 'deer',\n",
       " 'water',\n",
       " 'mobilesvary',\n",
       " 'turns',\n",
       " 'arng',\n",
       " 'installing',\n",
       " 'ishtamayoo',\n",
       " 'blame',\n",
       " 'members',\n",
       " 'trackmarque',\n",
       " 'prof',\n",
       " 'ibm',\n",
       " 'strokes',\n",
       " 'pod',\n",
       " 'pobox114',\n",
       " 'mila',\n",
       " 'shesil',\n",
       " '21',\n",
       " 'onluy',\n",
       " 'loosu',\n",
       " 'himself',\n",
       " 'robinson',\n",
       " 'hmm',\n",
       " 'omw',\n",
       " 'particularly',\n",
       " 'part',\n",
       " 'yours',\n",
       " 'bothering',\n",
       " 'coming',\n",
       " 'xxxxx',\n",
       " 'appreciated',\n",
       " 'dreams',\n",
       " 'nobbing',\n",
       " '1stchoice',\n",
       " 'lunchtime',\n",
       " 'apeshit',\n",
       " 'franxx',\n",
       " '08452810075over18',\n",
       " 'shldxxxx',\n",
       " '6089',\n",
       " 'facilities',\n",
       " 'exorcism',\n",
       " 'munsters',\n",
       " 'island',\n",
       " 'vco',\n",
       " 'mum',\n",
       " 'bloomberg',\n",
       " 'spin',\n",
       " 'consensus',\n",
       " 'greeting',\n",
       " 'chase',\n",
       " 'nicky',\n",
       " 'monthly',\n",
       " 'see',\n",
       " 'with',\n",
       " 'hanuman',\n",
       " 'fantastic',\n",
       " 'frwd',\n",
       " 'daddy',\n",
       " 'working',\n",
       " 'answering',\n",
       " 'crucify',\n",
       " 'wanting',\n",
       " 'afternon',\n",
       " '8714714',\n",
       " 'grr',\n",
       " 'ing',\n",
       " 'spjanuary',\n",
       " 'frnd',\n",
       " 'february',\n",
       " 'each',\n",
       " 'sea',\n",
       " 'outs',\n",
       " 'mahaveer',\n",
       " 'supply',\n",
       " 'wah',\n",
       " '63miles',\n",
       " 'affection',\n",
       " 'qatar',\n",
       " 'fren',\n",
       " 'shindig',\n",
       " 'langport',\n",
       " 'hence',\n",
       " 'kr',\n",
       " 'should',\n",
       " 'chicken',\n",
       " 'form',\n",
       " 'educational',\n",
       " 'yck',\n",
       " 'blimey',\n",
       " 'ic',\n",
       " 'hp',\n",
       " 'champ',\n",
       " 'sexual',\n",
       " 'dump',\n",
       " 'avenge',\n",
       " 'wihtuot',\n",
       " 'rebooting',\n",
       " 'sarcastic',\n",
       " 'river',\n",
       " 'rimac',\n",
       " 'portal',\n",
       " 'experience',\n",
       " 'memory',\n",
       " 'yun',\n",
       " 'sense',\n",
       " 'dizzamn',\n",
       " '150p16',\n",
       " 'shoppin',\n",
       " 'walsall',\n",
       " 'banter',\n",
       " 'tightly',\n",
       " '5226',\n",
       " 'india',\n",
       " 'nose',\n",
       " 'bother',\n",
       " 'braved',\n",
       " 'coca',\n",
       " 'kidding',\n",
       " 'women',\n",
       " 'essay',\n",
       " 'bootydelious',\n",
       " 'difference',\n",
       " 'like',\n",
       " 'bpo',\n",
       " 'praying',\n",
       " '08714342399',\n",
       " 'request',\n",
       " 'marry',\n",
       " 'hugh',\n",
       " 'ctagg',\n",
       " '820554ad0a1705572711',\n",
       " '08715203694',\n",
       " 'mountain',\n",
       " 'frndship',\n",
       " 'lonely',\n",
       " '08700621170150p',\n",
       " 'received',\n",
       " 'lavender',\n",
       " 'doc',\n",
       " 'code',\n",
       " 'arguments',\n",
       " '08452810071',\n",
       " 'barcelona',\n",
       " 'taka',\n",
       " 'deficient',\n",
       " 'womdarfull',\n",
       " '4the',\n",
       " '83600',\n",
       " 'meetins',\n",
       " 'telephonic',\n",
       " 'deeraj',\n",
       " 'stop',\n",
       " 'lecturer',\n",
       " 'dance',\n",
       " 'calld',\n",
       " 'lyricalladie',\n",
       " '440',\n",
       " 'asa',\n",
       " '08718730666',\n",
       " 'prakasamanu',\n",
       " 'defeat',\n",
       " 'screaming',\n",
       " 'honesty',\n",
       " 'justbeen',\n",
       " 'agidhane',\n",
       " 'witot',\n",
       " 'lip',\n",
       " 'somewhat',\n",
       " 'parade',\n",
       " 'askd',\n",
       " 'attributed',\n",
       " 'sing',\n",
       " 'immediately',\n",
       " 'selection',\n",
       " 'approve',\n",
       " 'hamper',\n",
       " 'amanda',\n",
       " 'hell',\n",
       " 'box97n7qp',\n",
       " 'margin',\n",
       " 'didntgive',\n",
       " 'venaam',\n",
       " 'vpod',\n",
       " 'spree',\n",
       " 'haventcn',\n",
       " 'hop',\n",
       " 'evening',\n",
       " 'spirit',\n",
       " '08718730555',\n",
       " 'push',\n",
       " 'gei',\n",
       " 'dental',\n",
       " 'lotta',\n",
       " 'dine',\n",
       " 'possible',\n",
       " 'lastest',\n",
       " 'cannot',\n",
       " 'o2fwd',\n",
       " 'easter',\n",
       " 'ans',\n",
       " 'inshah',\n",
       " 'telphone',\n",
       " 'breaker',\n",
       " 'transfered',\n",
       " '09065069120',\n",
       " 'parking',\n",
       " 'reduce',\n",
       " 'cold',\n",
       " 'yeh',\n",
       " 'flame',\n",
       " 'youre',\n",
       " 'crammed',\n",
       " 'lands',\n",
       " 'games',\n",
       " 'expiry',\n",
       " 'qbank',\n",
       " 'slots',\n",
       " 'sn',\n",
       " 'landline',\n",
       " 'snowman',\n",
       " 'demand',\n",
       " 'pretsovru',\n",
       " 'packing',\n",
       " '83370',\n",
       " 'beauties',\n",
       " 'here',\n",
       " 'tuth',\n",
       " 'chip',\n",
       " 'olayiwola',\n",
       " 'gibe',\n",
       " 'since',\n",
       " 'bubbletext',\n",
       " 'teach',\n",
       " 'coping',\n",
       " 'united',\n",
       " 'somewheresomeone',\n",
       " 'sterling',\n",
       " 'nails',\n",
       " 'route',\n",
       " 'drops',\n",
       " 'destiny',\n",
       " 'dedicate',\n",
       " 'log',\n",
       " 'roommates',\n",
       " 'westonzoyland',\n",
       " 'numbers',\n",
       " 'csbcm4235wc1n3xx',\n",
       " 'youuuuu',\n",
       " 'goodnite',\n",
       " 'mailed',\n",
       " 'relation',\n",
       " 'aunty',\n",
       " 'beendropping',\n",
       " 'alto18',\n",
       " '447801259231',\n",
       " 'fools',\n",
       " '750',\n",
       " '74355',\n",
       " 'multis',\n",
       " 'social',\n",
       " 'continued',\n",
       " 'zealand',\n",
       " 'naseeb',\n",
       " 'londn',\n",
       " 'belligerent',\n",
       " 'skills',\n",
       " 'passes',\n",
       " 'nyt',\n",
       " 'occur',\n",
       " 'edge',\n",
       " 'paper',\n",
       " 'irene',\n",
       " 'been',\n",
       " 'else',\n",
       " '0578',\n",
       " 'tech',\n",
       " 'standard',\n",
       " 'captaining',\n",
       " 'wo',\n",
       " 'two',\n",
       " 'havnt',\n",
       " 'bruv',\n",
       " 'o',\n",
       " 'yest',\n",
       " 'invest',\n",
       " 'processed',\n",
       " 'anywhere',\n",
       " 'pt2',\n",
       " 'fool',\n",
       " 'urgoin',\n",
       " 'canlove',\n",
       " '80062',\n",
       " 'affectionate',\n",
       " 'dogwood',\n",
       " 'soz',\n",
       " 'novelty',\n",
       " 'convenience',\n",
       " 'usually',\n",
       " 'another',\n",
       " 'ere',\n",
       " 'college',\n",
       " 'meets',\n",
       " 'ref',\n",
       " 'hearing',\n",
       " 'mag',\n",
       " '2channel',\n",
       " '9755',\n",
       " 'kappa',\n",
       " 'clock',\n",
       " 'havent',\n",
       " 'btwn',\n",
       " 'nottingham',\n",
       " '08719181259',\n",
       " 'save',\n",
       " 'take',\n",
       " 'california',\n",
       " 'woul',\n",
       " '1000call',\n",
       " 'oxygen',\n",
       " 'ab',\n",
       " 'cuppa',\n",
       " 'goes',\n",
       " 'vodafone',\n",
       " 'talkin',\n",
       " 'o2',\n",
       " 'cc100p',\n",
       " 'nutter',\n",
       " 'bstfrnd',\n",
       " 'break',\n",
       " 'perfume',\n",
       " '250k',\n",
       " '1405',\n",
       " 'conform',\n",
       " 'jeans',\n",
       " 'fear',\n",
       " 'invaders',\n",
       " 'frying',\n",
       " 'xin',\n",
       " 'birthday',\n",
       " 'ouch',\n",
       " '5p',\n",
       " '08712317606',\n",
       " 'kip',\n",
       " '09061701461',\n",
       " '861',\n",
       " 'do',\n",
       " 'obviously',\n",
       " 'path',\n",
       " 'before',\n",
       " 'woods',\n",
       " 'boss',\n",
       " 'showed',\n",
       " 'clocks',\n",
       " 'karaoke',\n",
       " 'reunion',\n",
       " 'cuddling',\n",
       " 'lv',\n",
       " 'make',\n",
       " 'beer',\n",
       " 'bhayandar',\n",
       " 'fantasy',\n",
       " 'tall',\n",
       " 'shortcode',\n",
       " 'pete',\n",
       " 'maid',\n",
       " 'jokes',\n",
       " 'feathery',\n",
       " 'ideas',\n",
       " 'happy',\n",
       " 'kegger',\n",
       " 'bitching',\n",
       " 'apparently',\n",
       " 'box245c2150pm',\n",
       " 'pee',\n",
       " '150pm',\n",
       " '87077',\n",
       " 'weaseling',\n",
       " 'recorded',\n",
       " 'supervisor',\n",
       " 'lacking',\n",
       " '09065989182',\n",
       " 'plm',\n",
       " 'blowing',\n",
       " 'following',\n",
       " 'listening2the',\n",
       " '09050000878',\n",
       " 'height',\n",
       " '125gift',\n",
       " 'pist',\n",
       " '420',\n",
       " 'panther',\n",
       " 'moral',\n",
       " 'today',\n",
       " 'wrong',\n",
       " '630',\n",
       " '30pm',\n",
       " 'jeremiah',\n",
       " '08715203677',\n",
       " 'division',\n",
       " 'paying',\n",
       " 'squatting',\n",
       " 'hsbc',\n",
       " 'deliveredtomorrow',\n",
       " 'babe',\n",
       " 'remember',\n",
       " 'reverse',\n",
       " 'der',\n",
       " 'eyes',\n",
       " 'bookshelf',\n",
       " 'panalam',\n",
       " 'download',\n",
       " 'stress',\n",
       " 'cm2',\n",
       " 'dorothy',\n",
       " 'appeal',\n",
       " 'opened',\n",
       " 'av',\n",
       " 'ring',\n",
       " 'temper',\n",
       " 'arrested',\n",
       " 'creativity',\n",
       " 'algebra',\n",
       " 'party',\n",
       " 'visit',\n",
       " 'deus',\n",
       " '33',\n",
       " 'bag',\n",
       " 'agency',\n",
       " 'varma',\n",
       " 'virgins',\n",
       " 'saturday',\n",
       " 'kill',\n",
       " 's',\n",
       " 'sunroof',\n",
       " 'unsubscribe',\n",
       " 'sculpture',\n",
       " 'care',\n",
       " '50',\n",
       " 'wise',\n",
       " 'intelligent',\n",
       " 'upgrade',\n",
       " '2morro',\n",
       " 'tolerance',\n",
       " 't4get2text',\n",
       " '08706091795',\n",
       " 'ntt',\n",
       " 'bold2',\n",
       " 'misss',\n",
       " 'infernal',\n",
       " 'nri',\n",
       " 'dumb',\n",
       " 'harri',\n",
       " 'di',\n",
       " '09058091870',\n",
       " 'has',\n",
       " 'meet',\n",
       " 'meetin',\n",
       " 'tones2u',\n",
       " 'ee',\n",
       " 'aa',\n",
       " 'princes',\n",
       " 'adsense',\n",
       " 'update',\n",
       " 'upstairs',\n",
       " '177',\n",
       " 'wc1n',\n",
       " 'lotto',\n",
       " 'fixes',\n",
       " 'fffff',\n",
       " 'crack',\n",
       " 'alot',\n",
       " 'cmon',\n",
       " 'hesitation',\n",
       " '08002888812',\n",
       " 'ileave',\n",
       " 'lol',\n",
       " 'nver',\n",
       " 'belive',\n",
       " 'normal',\n",
       " 'compare',\n",
       " 'sunday',\n",
       " 'priya',\n",
       " 'officially',\n",
       " 'meg',\n",
       " 'dark',\n",
       " 'zoom',\n",
       " 'apt',\n",
       " '67441233',\n",
       " 'bbdeluxe',\n",
       " 'formatting',\n",
       " 'by',\n",
       " 'watch',\n",
       " 'team',\n",
       " '2optout',\n",
       " 'rubber',\n",
       " 'middle',\n",
       " 'flatter',\n",
       " 'meeting',\n",
       " 'corect',\n",
       " 'certificate',\n",
       " 'place',\n",
       " 'sometimes',\n",
       " 'evo',\n",
       " 'forgiveness',\n",
       " '87239',\n",
       " 'piah',\n",
       " 'reffering',\n",
       " 'erotic',\n",
       " 'vatian',\n",
       " 'dhorte',\n",
       " 'xxx',\n",
       " 'atlast',\n",
       " '8077',\n",
       " '69888nyt',\n",
       " 'rentl',\n",
       " 'twelve',\n",
       " 'hurried',\n",
       " 'sura',\n",
       " 'swalpa',\n",
       " 'ws',\n",
       " 'bill',\n",
       " 'cudnt',\n",
       " 'tears',\n",
       " 'tuition',\n",
       " 'jeevithathile',\n",
       " 'maniac',\n",
       " 'celeb',\n",
       " 'fires',\n",
       " 'wrnog',\n",
       " 'hun',\n",
       " 'wrkin',\n",
       " 'seeing',\n",
       " 'awaiting',\n",
       " '09066368753',\n",
       " 'lions',\n",
       " '1yf',\n",
       " 'mcfly',\n",
       " 'prescription',\n",
       " 'instituitions',\n",
       " 'names',\n",
       " 'conclusion',\n",
       " 'roommate',\n",
       " 'him',\n",
       " 'gal',\n",
       " 'babies',\n",
       " 'eruku',\n",
       " '7250',\n",
       " 'haha',\n",
       " 'inconsiderate',\n",
       " '1500',\n",
       " 'other',\n",
       " 'yourself',\n",
       " 'daily',\n",
       " 'thesis',\n",
       " 'u',\n",
       " 'sry',\n",
       " 'british',\n",
       " 'software',\n",
       " 'including',\n",
       " 'bedroom',\n",
       " 'none',\n",
       " 'gpu',\n",
       " 'brownies',\n",
       " 'strict',\n",
       " 'lakhs',\n",
       " 'thandiyachu',\n",
       " 'landing',\n",
       " 'all',\n",
       " 'information',\n",
       " 'tex',\n",
       " 'host',\n",
       " 'im',\n",
       " 'dena',\n",
       " 'planning',\n",
       " 'festival',\n",
       " 'bleak',\n",
       " 'christians',\n",
       " 'barely',\n",
       " 'woken',\n",
       " 'blood',\n",
       " 'spoons',\n",
       " 'her',\n",
       " 'nights',\n",
       " 'urgently',\n",
       " 'luks',\n",
       " 'cres',\n",
       " 'lovely',\n",
       " 'thin',\n",
       " 'laid',\n",
       " 'callertune',\n",
       " 'starshine',\n",
       " 'century',\n",
       " 'b4280703',\n",
       " 'thout',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secret</th>\n",
       "      <th>prize</th>\n",
       "      <th>claim</th>\n",
       "      <th>now</th>\n",
       "      <th>coming</th>\n",
       "      <th>to</th>\n",
       "      <th>my</th>\n",
       "      <th>party</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secret  prize  claim  now  coming  to  my  party  winner\n",
       "0       2      2      1    1       0   0   0      0       0\n",
       "1       1      0      0    0       1   1   1      1       0\n",
       "2       1      1      1    1       0   0   0      0       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms = {'secret': [2,1,1],\n",
    "                       'prize': [2,0,1],\n",
    "                       'claim': [1,0,1],\n",
    "                       'now': [1,0,1],\n",
    "                       'coming': [0,1,0],\n",
    "                       'to': [0,1,0],\n",
    "                       'my': [0,1,0],\n",
    "                       'party': [0,1,0],\n",
    "                       'winner': [0,0,1]\n",
    "                      }\n",
    "\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "   for word in sms:\n",
    "      word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pura</th>\n",
       "      <th>rough</th>\n",
       "      <th>stone</th>\n",
       "      <th>ente</th>\n",
       "      <th>st</th>\n",
       "      <th>idk</th>\n",
       "      <th>violet</th>\n",
       "      <th>spouse</th>\n",
       "      <th>sleepin</th>\n",
       "      <th>169</th>\n",
       "      <th>...</th>\n",
       "      <th>8wp</th>\n",
       "      <th>safely</th>\n",
       "      <th>3optical</th>\n",
       "      <th>wot</th>\n",
       "      <th>history</th>\n",
       "      <th>quizclub</th>\n",
       "      <th>shb</th>\n",
       "      <th>ijust</th>\n",
       "      <th>description</th>\n",
       "      <th>jsut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7719 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pura  rough  stone  ente  st  idk  violet  spouse  sleepin  169  ...  8wp  \\\n",
       "0     0      0      0     0   0    0       0       0        0    0  ...    0   \n",
       "1     0      0      0     0   0    0       0       0        0    0  ...    0   \n",
       "2     0      0      0     0   0    0       0       0        0    0  ...    0   \n",
       "3     0      0      0     0   0    0       0       0        0    0  ...    0   \n",
       "4     0      0      0     0   0    0       0       0        0    0  ...    0   \n",
       "\n",
       "   safely  3optical  wot  history  quizclub  shb  ijust  description  jsut  \n",
       "0       0         0    0        0         0    0      0            0     0  \n",
       "1       0         0    0        0         0    0      0            0     0  \n",
       "2       0         0    0        0         0    0      0            0     0  \n",
       "3       0         0    0        0         0    0      0            0     0  \n",
       "4       0         0    0        0         0    0      0            0     0  \n",
       "\n",
       "[5 rows x 7719 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>pura</th>\n",
       "      <th>rough</th>\n",
       "      <th>stone</th>\n",
       "      <th>ente</th>\n",
       "      <th>st</th>\n",
       "      <th>idk</th>\n",
       "      <th>violet</th>\n",
       "      <th>spouse</th>\n",
       "      <th>...</th>\n",
       "      <th>8wp</th>\n",
       "      <th>safely</th>\n",
       "      <th>3optical</th>\n",
       "      <th>wot</th>\n",
       "      <th>history</th>\n",
       "      <th>quizclub</th>\n",
       "      <th>shb</th>\n",
       "      <th>ijust</th>\n",
       "      <th>description</th>\n",
       "      <th>jsut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[convey, my, regards, to, him]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[_, anyway, many, good, evenings, to, u, s]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[my, sort, code, is, and, acc, no, is, the, ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[sorry, i, din, lock, my, keypad]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>[hi, babe, its, chloe, how, r, u, i, was, smas...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  pura  rough  \\\n",
       "0   ham                     [convey, my, regards, to, him]     0      0   \n",
       "1   ham        [_, anyway, many, good, evenings, to, u, s]     0      0   \n",
       "2   ham  [my, sort, code, is, and, acc, no, is, the, ba...     0      0   \n",
       "3   ham                  [sorry, i, din, lock, my, keypad]     0      0   \n",
       "4  spam  [hi, babe, its, chloe, how, r, u, i, was, smas...     0      0   \n",
       "\n",
       "   stone  ente  st  idk  violet  spouse  ...  8wp  safely  3optical  wot  \\\n",
       "0      0     0   0    0       0       0  ...    0       0         0    0   \n",
       "1      0     0   0    0       0       0  ...    0       0         0    0   \n",
       "2      0     0   0    0       0       0  ...    0       0         0    0   \n",
       "3      0     0   0    0       0       0  ...    0       0         0    0   \n",
       "4      0     0   0    0       0       0  ...    0       0         0    0   \n",
       "\n",
       "   history  quizclub  shb  ijust  description  jsut  \n",
       "0        0         0    0      0            0     0  \n",
       "1        0         0    0      0            0     0  \n",
       "2        0         0    0      0            0     0  \n",
       "3        0         0    0      0            0     0  \n",
       "4        0         0    0      0            0     0  \n",
       "\n",
       "[5 rows x 7721 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "   n_word_given_spam = spam_messages[word].sum() # spam_messages already defined\n",
    "   p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "   parameters_spam[word] = p_word_given_spam\n",
    "\n",
    "   n_word_given_ham = ham_messages[word].sum() # ham_messages already defined\n",
    "   p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "   parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "   '''\n",
    "   message: a string\n",
    "   '''\n",
    "\n",
    "   message = re.sub('\\W', ' ', message)\n",
    "   message = message.lower().split()\n",
    "\n",
    "   p_spam_given_message = p_spam\n",
    "   p_ham_given_message = p_ham\n",
    "\n",
    "   for word in message:\n",
    "      if word in parameters_spam:\n",
    "         p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "      if word in parameters_ham: \n",
    "         p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "   print('P(Spam|message):', p_spam_given_message)\n",
    "   print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "   if p_ham_given_message > p_spam_given_message:\n",
    "      print('Label: Ham')\n",
    "   elif p_ham_given_message < p_spam_given_message:\n",
    "      print('Label: Spam')\n",
    "   else:\n",
    "      print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 8.469800467922538e-26\n",
      "P(Ham|message): 3.1787527555576857e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 5.373603496981814e-25\n",
      "P(Ham|message): 4.1000791683599846e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "   '''\n",
    "   message: a string\n",
    "   '''\n",
    "\n",
    "   message = re.sub('\\W', ' ', message)\n",
    "   message = message.lower().split()\n",
    "\n",
    "   p_spam_given_message = p_spam\n",
    "   p_ham_given_message = p_ham\n",
    "\n",
    "   for word in message:\n",
    "      if word in parameters_spam:\n",
    "         p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "      if word in parameters_ham:\n",
    "         p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "   if p_ham_given_message > p_spam_given_message:\n",
    "      return 'ham'\n",
    "   elif p_spam_given_message > p_ham_given_message:\n",
    "      return 'spam'\n",
    "   else:\n",
    "      return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>S...from the training manual it show there is ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Do you want a new Video phone? 600 anytime any...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>True. Its easier with her here.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Midnight at the earliest</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  S...from the training manual it show there is ...       ham\n",
       "1  spam  Do you want a new Video phone? 600 anytime any...      spam\n",
       "2   ham                    True. Its easier with her here.       ham\n",
       "3   ham                           Midnight at the earliest       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1107\n",
      "Incorrect: 7\n",
      "Accuracy: 0.9937163375224417\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "   row = row[1]\n",
    "   if row['Label'] == row['predicted']:\n",
    "      correct += 1\n",
    "\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes model accuracy(in %): 95.0\n"
     ]
    }
   ],
   "source": [
    "#Source: https://www.geeksforgeeks.org/naive-bayes-classifiers/?ref=lbp\n",
    "# load the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    " \n",
    "# store the feature matrix (X) and response vector (y)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    " \n",
    "# splitting X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    " \n",
    "# training the model on training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    " \n",
    "# making predictions on the testing set\n",
    "y_pred = gnb.predict(X_test)\n",
    " \n",
    "# comparing actual response values (y_test) with predicted response values (y_pred)\n",
    "from sklearn import metrics\n",
    "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
